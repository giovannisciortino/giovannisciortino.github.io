<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.19.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>HA two node GPFS cluster with tie-breaker disk - SYSADMIN CONTINUOUS IMPROVEMENT</title>
<meta name="description" content="In a previous post I described how configure a GPFS cluster filesystem ( a filesystem that can be mounted by two or more servers simultaneously ). This article describes the changes required to enable a high-availability configuration for a GPFS cluster filesystem. This configuration allows each node to write and read the filesystem when the other node is down. ">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="SYSADMIN CONTINUOUS IMPROVEMENT">
<meta property="og:title" content="HA two node GPFS cluster with tie-breaker disk">
<meta property="og:url" content="/test/2015/05/23/ha_two_node_gpfs_cluster_with_tie-breaker_disk.html">


  <meta property="og:description" content="In a previous post I described how configure a GPFS cluster filesystem ( a filesystem that can be mounted by two or more servers simultaneously ). This article describes the changes required to enable a high-availability configuration for a GPFS cluster filesystem. This configuration allows each node to write and read the filesystem when the other node is down. ">







  <meta property="article:published_time" content="2015-05-23T00:00:00+00:00">






<link rel="canonical" href="/test/2015/05/23/ha_two_node_gpfs_cluster_with_tie-breaker_disk.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "/test/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/test/feed.xml" type="application/atom+xml" rel="alternate" title="SYSADMIN CONTINUOUS IMPROVEMENT Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/test/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/test/"><img src="/test/assets/logo_sysadminci.png" alt=""></a>
        
        <a class="site-title" href="/test/">
          SYSADMIN CONTINUOUS IMPROVEMENT
          <span class="site-subtitle">Useful tips and tools for system administrators</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/test/about/">About me</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">TAGS</span>
        

        
        <ul>
          
            <li><a href="/test/tag/apache">apache</a></li>
          
            <li><a href="/test/tag/automation">automation</a></li>
          
            <li><a href="/test/tag/cluster">cluster</a></li>
          
            <li><a href="/test/tag/flume">flume</a></li>
          
            <li><a href="/test/tag/git">git</a></li>
          
            <li><a href="/test/tag/github">github</a></li>
          
            <li><a href="/test/tag/hadoop">hadoop</a></li>
          
            <li><a href="/test/tag/haproxy">haproxy</a></li>
          
            <li><a href="/test/tag/jekyll">jekyll</a></li>
          
            <li><a href="/test/tag/linux">linux</a></li>
          
            <li><a href="/test/tag/python">python</a></li>
          
            <li><a href="/test/tag/spark">spark</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="HA two node GPFS cluster with tie-breaker disk">
    <meta itemprop="description" content="In a previous post I described how configure a GPFS cluster filesystem ( a filesystem that can be mounted by two or more servers simultaneously ).This article describes the changes required to enable a high-availability configuration for a GPFS cluster filesystem. This configuration allows each node to write and read the filesystem when the other node is down.">
    <meta itemprop="datePublished" content="2015-05-23T00:00:00+00:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">HA two node GPFS cluster with tie-breaker disk
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>In a previous post I described how configure a GPFS cluster filesystem ( a filesystem that can be mounted by two or more servers simultaneously ).
This article describes the changes required to enable a high-availability configuration for a GPFS cluster filesystem. This configuration allows each node to write and read the filesystem when the other node is down.</p>

<p>The physical server architecture, showed in the following figure, remains the same:</p>
<ul>
  <li>two Centos server</li>
  <li>two shared disks between the servers</li>
</ul>

<p><img src="/assets/2015-05-23-ha_two_node_gpfs_cluster_with_tie-breaker_disk_img1.jpg" alt="gpfs architecture diagram" class="center-image" /></p>

<p>The command mmlscluster output shows that only the first gpfs node has assigned the role of manager and quorum node. In order to enable high-availability both the servers must have these two roles.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>root@gpfs01 ~]# /usr/lpp/mmfs/bin/mmlscluster

GPFS cluster information
<span class="o">========================</span>
  GPFS cluster name:         gpfs01
  GPFS cluster <span class="nb">id</span>:           14526312809412325839
  GPFS UID domain:           gpfs01
  Remote shell <span class="nb">command</span>:      /usr/bin/ssh
  Remote file copy <span class="nb">command</span>:  /usr/bin/scp
  Repository <span class="nb">type</span>:           CCR

 Node  Daemon node name  IP address    Admin node name  Designation
<span class="nt">--------------------------------------------------------------------</span>
   1   gpfs01            172.17.0.101  gpfs01           quorum-manager
   2   gpfs02            172.17.0.102  gpfs02</code></pre></figure>

<p>The filesystem fs_gpfs01 is composed by two network shared disk. In this post I’ll show how configure thee two disks as tie-breaker disks in order to enable the high-availability.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>root@gpfs01 ~]# /usr/lpp/mmfs/bin/mmlsnsd <span class="nt">-a</span>

File system Disk name NSD servers
<span class="nt">---------------------------------------------------------------------------</span>
fs_gpfs01 mynsd1 <span class="o">(</span>directly attached<span class="o">)</span>
fs_gpfs01 mynsd2 <span class="o">(</span>directly attached<span class="o">)</span></code></pre></figure>

<p>Indeed as many other cluster softwares GPFS requires that the majority of quorum nodes are online to use the filesystem in order to avoid split brain.
In this case the cluster is composed by an even number of cluster nodes so one or more tie-breaker disk must be defined.
More details about gpfs reliability configuration can be found in this document <a href="http://www-03.ibm.com/systems/resources/configure-gpfs-for-reliability.pdf">http://www-03.ibm.com/systems/resources/configure-gpfs-for-reliability.pdf</a> .</p>

<p>As described before I assign the manager and quorum role to node gpfs02 and I verify it using the command mmlscluster.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>root@gpfs01 ~]# mmchnode <span class="nt">--manager</span> <span class="nt">-N</span> gpfs02
Thu May 7 22:11:20 CEST 2015: mmchnode: Processing node gpfs02
mmchnode: Propagating the cluster configuration data to all
affected nodes. This is an asynchronous process.

<span class="o">[</span>root@gpfs01 ~]# mmchnode <span class="nt">--quorum</span> <span class="nt">-N</span> gpfs02
Thu May 7 22:11:20 CEST 2015: mmchnode: Processing node gpfs02
mmchnode: Propagating the cluster configuration data to all
affected nodes. This is an asynchronous process.
<span class="o">[</span>root@gpfs01 ~]# /usr/lpp/mmfs/bin/mmlscluster

GPFS cluster information
<span class="o">========================</span>
GPFS cluster name: gpfs01
GPFS cluster <span class="nb">id</span>: 14526312809412325839
GPFS UID domain: gpfs01
Remote shell <span class="nb">command</span>: /usr/bin/ssh
Remote file copy <span class="nb">command</span>: /usr/bin/scp
Repository <span class="nb">type</span>: CCR

Node Daemon node name IP address Admin node name Designation
<span class="nt">--------------------------------------------------------------------</span>
1 gpfs01 172.17.0.101 gpfs01 quorum-manager
2 gpfs02 172.17.0.102 gpfs02 quorum-manager</code></pre></figure>

<p>I configure both NSD as tie-breaker disks and I verify it using the command mmlsconfig</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>root@gpfs01 ~]# mmchconfig <span class="nv">tiebreakerDisks</span><span class="o">=</span><span class="s2">"mynsd1;mynsd2"</span>

<span class="o">[</span>root@gpfs01 ~]# mmlsconfig
Configuration data <span class="k">for </span>cluster gpfs01:
<span class="nt">--------------------------------------</span>
clusterName gpfs01
clusterId 14526312809412325839
autoload no
dmapiFileHandleSize 32
minReleaseLevel 4.1.0.4
ccrEnabled <span class="nb">yes
</span>tiebreakerDisks mynsd1<span class="p">;</span>mynsd2
adminMode central

File systems <span class="k">in </span>cluster gpfs01:
<span class="nt">-------------------------------</span>
/dev/fs_gpfs01</code></pre></figure>

<p>Now the GPFS HA configuration is completed. I can shutdown one node and verify that the other node can write and read the GPFS filesystem.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>root@gpfs01 ~]# mmmount /fs_gpfs01 <span class="nt">-a</span>
Thu May 7 22:22:42 CEST 2015: mmmount: Mounting file systems ...

<span class="o">[</span>root@gpfs02 ~]# ssh gpfs01 shutdown <span class="nt">-h</span> now
<span class="o">[</span>root@gpfs02 ~]# <span class="nb">cd</span> /fs_gpfs01/
<span class="o">[</span>root@gpfs02 fs_gpfs01]# <span class="nb">ls</span> <span class="nt">-latr</span>
dr-xr-xr-x 2 root root 8192 Jan 1 1970 .snapshots
<span class="o">[</span>root@gpfs02 fs_gpfs01]# <span class="nb">ls</span> <span class="nt">-latr</span>
total 1285
dr-xr-xr-x 2 root root 8192 Jan 1 1970 .snapshots
drwxr-xr-x 2 root root 262144 May 7 21:49 <span class="nb">.</span>
<span class="nt">-rw-r--r--</span> 1 root root 1048576 May 7 21:50 test1M
dr-xr-xr-x. 24 root root 4096 May 7 21:55 ..</code></pre></figure>

<p>Furthermore the log in /var/log/messages provides more details about this event. The log below,grabbed on node gpfs02 when I shutdown the node gpfs01, shows that the node gpfs02 detected the failure of the node gpfs01 and it has been elected cluster manager.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># /var/log/messages</span>
...
May 7 22:25:29 gpfs02 mmfs: <span class="o">[</span>E] CCR: failed to connect to node 172.17.0.101:1191 <span class="o">(</span>sock 42 err 1143<span class="o">)</span>
May 7 22:25:39 gpfs02 mmfs: <span class="o">[</span>E] CCR: failed to connect to node 172.17.0.101:1191 <span class="o">(</span>sock 42 err 1143<span class="o">)</span>
May 7 22:25:39 gpfs02 mmfs: <span class="o">[</span>E] Node 172.17.0.101 <span class="o">(</span>gpfs01<span class="o">)</span> is being expelled due to expired lease.
May 7 22:25:39 gpfs02 mmfs: <span class="o">[</span>N] This node <span class="o">(</span>172.17.0.102 <span class="o">(</span>gpfs02<span class="o">))</span> is now Cluster Manager <span class="k">for </span>gpfs01.</code></pre></figure>


        
      </section>

      <footer class="page__meta">
        
        


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2015-05-23T00:00:00+00:00">May 23, 2015</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/test/2015/05/09/install_cloudera_prerequisites_with_ansible.html" class="pagination--pager" title="Install Cloudera prerequisites with Ansible
">Previous</a>
    
    
      <a href="/test/2015/07/06/flume_import_apache_logs_in_hadoop_hdfs.html" class="pagination--pager" title="Flume: Import apache logs in hadoop hdfs
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/test/2020/05/06/satellite_6_reporting_engine_system_currency_report.html" rel="permalink">Red Hat Satellite 6 reporting engine - System currency report
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">This post describe how generate the “System currency” report in Red Hat Satellite 6.
System currency report is a report already existing in Satellite 5, belo...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/test/2020/04/05/use_github_actions_to_create_jekyll_post_from_github_issue.html" rel="permalink">Use GitHub Actions to create Jekyll post from GitHub issue
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">This post describe a GitHub Actions workflow that allow to create new post on a Jekyll web site contained in a GitHub repository using the issue editor of Gi...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/test/2016/03/01/distrubuted_sql_query_using_sparksql_hdfs_sqoop.html" rel="permalink">Distributed SQL Query using SparkSQL, HDFS and Sqoop
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">Spark SQL: A brief introduction
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/test/2016/02/16/apache_spark_distributed_computation_of_pi_in_8_lines_of_python_code.html" rel="permalink">Apache Spark – Distributed computation of π in 8 lines of Python code
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">In this post I show how to write a distributed application computing an approximation of pi number though a Spark application using Python.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <li><a href="/test/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 SYSADMIN CONTINUOUS IMPROVEMENT. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/test/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>










  </body>
</html>
